{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VerlonRoelMBINGUI/Computer_Vision_Project_AMMI2023/blob/main/Bourbaki_CV_Cassava_Project_Kaggle_Good_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Team members :\n",
        "\n",
        "1. Dieu - Donne FANGNON\n",
        "2. Verlon Roel MBINGUI"
      ],
      "metadata": {
        "id": "GLprKy--22xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cassava Disease Classification\n",
        "Classify pictures of cassava leaves into 1 of 4 disease categories (or healthy)\n",
        "\n",
        "\n",
        "AMMI 2023 Competition : rank 1/20"
      ],
      "metadata": {
        "id": "5-FKtYSh3VMn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zsh8nV9i3IoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ttach"
      ],
      "metadata": {
        "id": "HqyOPyM0B1qn",
        "outputId": "ae0d0cc5-92f6-4e5d-ade1-9dbb00c5c79d",
        "execution": {
          "iopub.status.busy": "2023-05-21T07:34:52.307362Z",
          "iopub.execute_input": "2023-05-21T07:34:52.307742Z",
          "iopub.status.idle": "2023-05-21T07:35:06.896020Z",
          "shell.execute_reply.started": "2023-05-21T07:34:52.307711Z",
          "shell.execute_reply": "2023-05-21T07:35:06.894483Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting ttach\n  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\nInstalling collected packages: ttach\nSuccessfully installed ttach-0.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/gbaydin/hypergradient-descent.git\n",
        "\n",
        "from hypergrad import SGDHD, AdamHD"
      ],
      "metadata": {
        "id": "NOu9AZqjB1qq",
        "outputId": "31f1256e-1622-44cf-95f0-181cf4c4a782",
        "execution": {
          "iopub.status.busy": "2023-05-21T07:35:08.976817Z",
          "iopub.execute_input": "2023-05-21T07:35:08.977626Z",
          "iopub.status.idle": "2023-05-21T07:35:32.336691Z",
          "shell.execute_reply.started": "2023-05-21T07:35:08.977578Z",
          "shell.execute_reply": "2023-05-21T07:35:32.335613Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting git+https://github.com/gbaydin/hypergradient-descent.git\n  Cloning https://github.com/gbaydin/hypergradient-descent.git to /tmp/pip-req-build-g62ecxu7\n  Running command git clone --filter=blob:none --quiet https://github.com/gbaydin/hypergradient-descent.git /tmp/pip-req-build-g62ecxu7\n  Resolved https://github.com/gbaydin/hypergradient-descent.git to commit 020d6080c4cedfbc88d5cdb7a2a53f92b34c2b16\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: hypergrad\n  Building wheel for hypergrad (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for hypergrad: filename=hypergrad-0.1-py3-none-any.whl size=8199 sha256=2ee6ec14f29ac9104de1e10095c4465d3bc9a02975cb07284ffe5a4c8058252b\n  Stored in directory: /tmp/pip-ephem-wheel-cache-6pphychk/wheels/12/18/2f/fc715468b5745149d6d37c67b27ef8a4f5de487c90d71576b5\nSuccessfully built hypergrad\nInstalling collected packages: hypergrad\nSuccessfully installed hypergrad-0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pretrainedmodels"
      ],
      "metadata": {
        "id": "066bMesyB1qr",
        "outputId": "f389ea67-1bcc-4da3-ff66-83080eb2bd49",
        "execution": {
          "iopub.status.busy": "2023-05-21T07:35:34.947025Z",
          "iopub.execute_input": "2023-05-21T07:35:34.948287Z",
          "iopub.status.idle": "2023-05-21T07:35:48.604848Z",
          "shell.execute_reply.started": "2023-05-21T07:35:34.948238Z",
          "shell.execute_reply": "2023-05-21T07:35:48.603470Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting pretrainedmodels\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (0.15.1)\nRequirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (2.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels) (4.64.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from munch->pretrainedmodels) (1.16.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (4.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.11.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (3.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->pretrainedmodels) (1.11.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->pretrainedmodels) (9.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->pretrainedmodels) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->pretrainedmodels) (2.28.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->pretrainedmodels) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pretrainedmodels) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pretrainedmodels) (1.26.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pretrainedmodels) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->pretrainedmodels) (2022.12.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->pretrainedmodels) (1.3.0)\nBuilding wheels for collected packages: pretrainedmodels\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60966 sha256=2801f0a9e9a4e074dbcb81a566482253160516d9fdf19055b86fecb3b7be6060\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built pretrainedmodels\nInstalling collected packages: pretrainedmodels\nSuccessfully installed pretrainedmodels-0.7.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "id": "KsTII-SICTYo",
        "outputId": "267722db-b8c1-4f8f-ab13-571f111c71c6",
        "execution": {
          "iopub.status.busy": "2023-05-21T07:35:53.885087Z",
          "iopub.execute_input": "2023-05-21T07:35:53.886193Z",
          "iopub.status.idle": "2023-05-21T07:36:07.727899Z",
          "shell.execute_reply.started": "2023-05-21T07:35:53.886137Z",
          "shell.execute_reply": "2023-05-21T07:36:07.725300Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting efficientnet_pytorch\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet_pytorch) (2.0.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.11.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (1.11.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (4.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\nBuilding wheels for collected packages: efficientnet_pytorch\n  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=1569700598872a7a08e3ce783867dc4e101873bb23b93d87bdb0556fbc9f9cdb\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\nSuccessfully built efficientnet_pytorch\nInstalling collected packages: efficientnet_pytorch\nSuccessfully installed efficientnet_pytorch-0.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tmm"
      ],
      "metadata": {
        "trusted": true,
        "id": "EYUidzj-1lVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "\n",
        "import numpy    as np\n",
        "import datetime as dt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot   as plt\n",
        "\n",
        "from PIL               import Image\n",
        "from torch.utils.data  import Dataset\n",
        "from torch.autograd    import Variable\n",
        "from torch.optim       import lr_scheduler\n",
        "\n",
        "from torch.utils.data  import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision       import transforms, datasets, models\n",
        "from os                import listdir, makedirs, getcwd, remove\n",
        "from os.path           import isfile, join, abspath, exists, isdir, expanduser\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from hypergrad import SGDHD, AdamHD\n",
        "\n",
        "import pretrainedmodels\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "import ttach as tta\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "i3LoBOuBB1qr",
        "execution": {
          "iopub.status.busy": "2023-05-21T07:36:49.197584Z",
          "iopub.execute_input": "2023-05-21T07:36:49.198011Z",
          "iopub.status.idle": "2023-05-21T07:36:51.018578Z",
          "shell.execute_reply.started": "2023-05-21T07:36:49.197951Z",
          "shell.execute_reply": "2023-05-21T07:36:51.017625Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = \"SUBMISSION2\"\n",
        "\n",
        "MODEL_NAME1 = 'se_resnext101_32x4d' # could be fbresnet152 or inceptionresnetv2\n",
        "MODEL_NAME2 = 'efficientnet-b0'\n",
        "DIM_1 = 550\n",
        "DIM_2 = 500\n",
        "DIM_TEST_1 = 550\n",
        "DIM_TEST_2 = 500\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "NUM_EPOCHS1 = 11\n",
        "\n",
        "random_seed = 42\n",
        "shuffle_dataset = True\n",
        "validation_split = .1"
      ],
      "metadata": {
        "id": "5HETNaJ5B1qs",
        "execution": {
          "iopub.status.busy": "2023-05-21T19:03:52.116352Z",
          "iopub.execute_input": "2023-05-21T19:03:52.116768Z",
          "iopub.status.idle": "2023-05-21T19:03:52.124270Z",
          "shell.execute_reply.started": "2023-05-21T19:03:52.116738Z",
          "shell.execute_reply": "2023-05-21T19:03:52.123142Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "vUQi3oSrB1qt",
        "execution": {
          "iopub.status.busy": "2023-05-21T16:18:34.252324Z",
          "iopub.execute_input": "2023-05-21T16:18:34.252666Z",
          "iopub.status.idle": "2023-05-21T16:18:34.257881Z",
          "shell.execute_reply.started": "2023-05-21T16:18:34.252637Z",
          "shell.execute_reply": "2023-05-21T16:18:34.256684Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/kaggle/input/ammi-2023-convnets\"\n",
        "train_path = join(data_path, \"train/train\")\n",
        "test_path = join(data_path,\"test/test\")\n",
        "extraimage_path = join(data_path, \"extraimages/extraimages\")"
      ],
      "metadata": {
        "id": "eCENs2WvB1qt",
        "execution": {
          "iopub.status.busy": "2023-05-21T16:18:35.061361Z",
          "iopub.execute_input": "2023-05-21T16:18:35.061713Z",
          "iopub.status.idle": "2023-05-21T16:18:35.066836Z",
          "shell.execute_reply.started": "2023-05-21T16:18:35.061683Z",
          "shell.execute_reply": "2023-05-21T16:18:35.065743Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6WaJB9NCwGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0y8NQTDRCweN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3O3O8qqCggO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations for both the training and testing data\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "# Do data transforms here, Try many others\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.Resize(DIM_1),\n",
        "                                       transforms.RandomCrop(DIM_2),\n",
        "                                       transforms.RandomHorizontalFlip(0.3),\n",
        "                                       transforms.RandomVerticalFlip(0.3),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.RandomErasing(0.1),\n",
        "                                       transforms.Normalize(mean=mean, std=std)])\n",
        "\n",
        "test_transforms = transforms.Compose([ transforms.Resize(DIM_TEST_1),\n",
        "                                      transforms.CenterCrop(DIM_TEST_1),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=mean, std=std)])"
      ],
      "metadata": {
        "id": "jXMr-my0B1qu",
        "execution": {
          "iopub.status.busy": "2023-05-21T16:18:36.716875Z",
          "iopub.execute_input": "2023-05-21T16:18:36.717667Z",
          "iopub.status.idle": "2023-05-21T16:18:36.725674Z",
          "shell.execute_reply.started": "2023-05-21T16:18:36.717629Z",
          "shell.execute_reply": "2023-05-21T16:18:36.724444Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CassavaDataset(Dataset):\n",
        "    def __init__(self, path, dim, transform=None):\n",
        "        self.classes = os.listdir(path)\n",
        "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
        "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
        "        self.transform = transform\n",
        "        self.dim = dim\n",
        "\n",
        "        self.targets = []\n",
        "\n",
        "\n",
        "        files = []\n",
        "        for i, className in enumerate(self.classes):\n",
        "            for fileName in self.file_list[i]:\n",
        "                files.append([i, className, fileName])\n",
        "                self.targets.append(i)\n",
        "\n",
        "        self.file_list = files\n",
        "        files = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fileName = self.file_list[idx][2]\n",
        "        classCategory = self.file_list[idx][0]\n",
        "        im = Image.open(fileName)\n",
        "        if self.transform:\n",
        "            im = self.transform(im)\n",
        "\n",
        "        return im.view(3, self.dim, self.dim), classCategory\n",
        "\n",
        "class CassavaTestDataset(Dataset):\n",
        "    def __init__(self, path, dim, transform=None):\n",
        "        self.classes = os.listdir(path)\n",
        "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
        "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
        "        self.transform = transform\n",
        "        self.indices = []\n",
        "        self.dim=dim\n",
        "\n",
        "        files = []\n",
        "        for i, className in enumerate(self.classes):\n",
        "            for fileName in self.file_list[i]:\n",
        "                files.append([i, className, fileName])\n",
        "                self.indices.append(fileName.split(\"/\")[-1])\n",
        "        self.file_list = files\n",
        "        files = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fileName = self.file_list[idx][2]\n",
        "        index = self.file_list[idx][2]\n",
        "        im = Image.open(fileName)\n",
        "        if self.transform:\n",
        "            im = self.transform(im)\n",
        "\n",
        "        return im.view(3, self.dim, self.dim), index\n",
        "\n",
        "train_data = CassavaDataset(train_path, dim=DIM_2, transform=train_transforms)\n",
        "test_data = CassavaTestDataset(test_path, dim=DIM_TEST_1, transform=test_transforms)"
      ],
      "metadata": {
        "id": "9bX5DFgLB1qu",
        "execution": {
          "iopub.status.busy": "2023-05-21T16:18:37.109391Z",
          "iopub.execute_input": "2023-05-21T16:18:37.110013Z",
          "iopub.status.idle": "2023-05-21T16:18:37.183068Z",
          "shell.execute_reply.started": "2023-05-21T16:18:37.109949Z",
          "shell.execute_reply": "2023-05-21T16:18:37.182193Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.classes"
      ],
      "metadata": {
        "id": "QVyNneaIB1qv",
        "outputId": "df4903c3-1fac-4e47-9ebb-8d3788f7caf4",
        "execution": {
          "iopub.status.busy": "2023-05-21T16:18:37.881574Z",
          "iopub.execute_input": "2023-05-21T16:18:37.882533Z",
          "iopub.status.idle": "2023-05-21T16:18:37.888902Z",
          "shell.execute_reply.started": "2023-05-21T16:18:37.882488Z",
          "shell.execute_reply": "2023-05-21T16:18:37.888038Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['cmd', 'cbb', 'cbsd', 'healthy', 'cgm']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]"
      ],
      "metadata": {
        "id": "hMMT3ywFB1qw",
        "execution": {
          "iopub.status.busy": "2023-05-21T16:18:38.931114Z",
          "iopub.execute_input": "2023-05-21T16:18:38.931476Z",
          "iopub.status.idle": "2023-05-21T16:18:38.937879Z",
          "shell.execute_reply.started": "2023-05-21T16:18:38.931446Z",
          "shell.execute_reply": "2023-05-21T16:18:38.936984Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)"
      ],
      "metadata": {
        "id": "y04ehCdPB1qw",
        "execution": {
          "iopub.status.busy": "2023-05-21T16:18:40.072039Z",
          "iopub.execute_input": "2023-05-21T16:18:40.072713Z",
          "iopub.status.idle": "2023-05-21T16:18:40.077360Z",
          "shell.execute_reply.started": "2023-05-21T16:18:40.072678Z",
          "shell.execute_reply": "2023-05-21T16:18:40.076188Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                                             sampler=train_sampler)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                                             sampler=valid_sampler)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "7lz7xjquB1qw",
        "execution": {
          "iopub.status.busy": "2023-05-21T16:18:41.058947Z",
          "iopub.execute_input": "2023-05-21T16:18:41.059332Z",
          "iopub.status.idle": "2023-05-21T16:18:41.065449Z",
          "shell.execute_reply.started": "2023-05-21T16:18:41.059301Z",
          "shell.execute_reply": "2023-05-21T16:18:41.064376Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data_loader):\n",
        "    \"\"\"Measures the accuracy of a model on a data set.\"\"\"\n",
        "    # Make sure the model is in evaluation mode.\n",
        "    model.eval()\n",
        "    # We do not need to maintain intermediate activations while testing.\n",
        "    accs = []\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Loop over test data.\n",
        "        for features, target in data_loader:\n",
        "\n",
        "            # Forward pass.\n",
        "            output = model(features.to(device))\n",
        "\n",
        "            # Get the label corresponding to the highest predicted probability.\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "            # Count number of correct predictions.\n",
        "            correct = pred.cpu().eq(target.view_as(pred)).sum().item()\n",
        "            total = pred.shape[0]\n",
        "            accs.append(correct/total)\n",
        "\n",
        "    # Print test accuracy.\n",
        "    percent = 100. * np.mean(accs)\n",
        "    st = np.std(accs)\n",
        "    return percent, st\n",
        "\n",
        "def train(model, criterion, data_loader, test_data_loader, optimizer, num_epochs, filename):\n",
        "    \"\"\"Simple training loop for a PyTorch model.\"\"\"\n",
        "\n",
        "    # Make sure model is in training mode.\n",
        "    model.train()\n",
        "\n",
        "    # Move model to the device (CPU or GPU).\n",
        "    model.to(device)\n",
        "\n",
        "    # Exponential moving average of the loss.\n",
        "    ema_loss = None\n",
        "\n",
        "    best_acc = 0\n",
        "\n",
        "    print('----- Training Loop -----')\n",
        "    # Loop over epochs.\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Loop over data.\n",
        "        for batch_idx, (features, target) in enumerate(data_loader):\n",
        "\n",
        "            # Forward pass.\n",
        "            output = model(features.to(device))\n",
        "            loss = criterion(output.to(device), target.to(device))\n",
        "\n",
        "            # Backward pass.\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # NOTE: It is important to call .item() on the loss before summing.\n",
        "            if ema_loss is None:\n",
        "                ema_loss = loss.item()\n",
        "            else:\n",
        "                ema_loss += (loss.item() - ema_loss) * 0.01\n",
        "\n",
        "        # Print out progress the end of epoch.\n",
        "        print('----- Model Evaluation -----')\n",
        "        print('Epoch: {}/{} \\tTrain Loss: {:.6f}'.format(epoch+1,num_epochs, ema_loss))\n",
        "        train_a, train_st = test(model,data_loader)\n",
        "        test_a, test_st = test(model,test_data_loader)\n",
        "        print(f'Train accuracy: ({train_a:.2f}%) with std:({train_st:.2f})')\n",
        "        print(f'Test accuracy: ({test_a:.2f}%) with std:({test_st:.2f})')\n",
        "        if test_a > best_acc:\n",
        "            best_acc = test_a\n",
        "            torch.save(model.state_dict(), filename+\".pth\")\n",
        "\n",
        "    checkpoint = torch.load(filename+\".pth\")\n",
        "    model.load_state_dict(checkpoint)\n",
        "    print(\"------\")\n",
        "    test_a, test_st = test(model,test_data_loader)\n",
        "    print(f'Final test accuracy: ({test_a:.2f}%) with std:({test_st:.2f})')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def generate_predictions(model,data_loader):\n",
        "    model.eval()\n",
        "    preds=[]\n",
        "    idx=[]\n",
        "\n",
        "    print('----- MAKING PREDICTIONS -----')\n",
        "    # We do not need to maintain intermediate activations while testing.\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Loop over test data.\n",
        "        for features, indices in data_loader:\n",
        "\n",
        "            # Forward pass.\n",
        "            output = model(features.to(device))\n",
        "\n",
        "            # Get the label corresponding to the highest predicted probability.\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            for p,ind in zip(pred,indices):\n",
        "                idx.append(ind)\n",
        "                preds.append(p.item())\n",
        "\n",
        "    return preds,idx\n",
        "\n",
        "def map_to_classes(n):\n",
        "    return train_data.classes[n]"
      ],
      "metadata": {
        "id": "jD6kZ_lEB1qx",
        "execution": {
          "iopub.status.busy": "2023-05-21T16:18:42.762355Z",
          "iopub.execute_input": "2023-05-21T16:18:42.763200Z",
          "iopub.status.idle": "2023-05-21T16:18:42.798041Z",
          "shell.execute_reply.started": "2023-05-21T16:18:42.763144Z",
          "shell.execute_reply": "2023-05-21T16:18:42.796321Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_resnext(model_name):\n",
        "    model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "    model.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "    model.last_linear = nn.Linear(in_features=2048, out_features=5, bias=True)#2048\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = AdamHD(model.parameters(), lr=1e-4, hypergrad_lr=1e-9)\n",
        "\n",
        "    return model, criterion, optimizer\n",
        "\n",
        "def get_eff_net(model_name, dim=1280):\n",
        "    model = EfficientNet.from_pretrained(model_name)\n",
        "    model._fc = nn.Linear(in_features=dim, out_features=5, bias=True)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = AdamHD(model.parameters(), lr=1e-4, hypergrad_lr=1e-9)\n",
        "\n",
        "    return model, criterion, optimizer\n",
        "\n"
      ],
      "metadata": {
        "id": "pWwdEmQcB1qx",
        "execution": {
          "iopub.status.busy": "2023-05-21T19:04:13.084446Z",
          "iopub.execute_input": "2023-05-21T19:04:13.084844Z",
          "iopub.status.idle": "2023-05-21T19:04:13.093677Z",
          "shell.execute_reply.started": "2023-05-21T19:04:13.084814Z",
          "shell.execute_reply": "2023-05-21T19:04:13.092635Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []"
      ],
      "metadata": {
        "id": "lJsNchPSB1qx",
        "execution": {
          "iopub.status.busy": "2023-05-21T19:04:13.333766Z",
          "iopub.execute_input": "2023-05-21T19:04:13.334124Z",
          "iopub.status.idle": "2023-05-21T19:04:13.338320Z",
          "shell.execute_reply.started": "2023-05-21T19:04:13.334094Z",
          "shell.execute_reply": "2023-05-21T19:04:13.337375Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model1, criterion, optimizer = get_eff_net(MODEL_NAME2)\n",
        "# #model1, criterion, optimizer =get_eff_net( MODEL_NAME2 , dim=1280)\n",
        "# model1 = train(model1, criterion, train_loader, valid_loader, optimizer, num_epochs=NUM_EPOCHS1, filename=\"Resfin\")\n",
        "\n",
        "# tta_model = tta.ClassificationTTAWrapper(model1, tta.aliases.five_crop_transform(DIM_TEST_2,DIM_TEST_2))\n",
        "# predictions, _ = generate_predictions(tta_model,test_loader)\n",
        "# preds.append(predictions)\n",
        "\n",
        "model1, criterion, optimizer = get_eff_net(MODEL_NAME2)\n",
        "#model1, criterion, optimizer =get_eff_net( MODEL_NAME2 , dim=1280)\n",
        "model1 = train(model1, criterion, train_loader, valid_loader, optimizer, num_epochs=NUM_EPOCHS1, filename=\"Resfin\")\n",
        "\n",
        "tta_model = tta.ClassificationTTAWrapper(model1, tta.aliases.five_crop_transform(DIM_TEST_2,DIM_TEST_2))\n",
        "predictions, _ = generate_predictions(tta_model,test_loader)\n",
        "preds.append(predictions)"
      ],
      "metadata": {
        "id": "FJWrEuhzB1qy",
        "outputId": "07f0adbe-a86b-4255-835d-514e3252eeb5",
        "execution": {
          "iopub.status.busy": "2023-05-21T19:04:22.426343Z",
          "iopub.execute_input": "2023-05-21T19:04:22.426706Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Loaded pretrained weights for efficientnet-b0\n----- Training Loop -----\n----- Model Evaluation -----\nEpoch: 1/11 \tTrain Loss: 0.570839\nTrain accuracy: (89.12%) with std:(0.10)\nTest accuracy: (87.72%) with std:(0.11)\n----- Model Evaluation -----\nEpoch: 2/11 \tTrain Loss: 0.401023\nTrain accuracy: (88.73%) with std:(0.10)\nTest accuracy: (87.37%) with std:(0.10)\n----- Model Evaluation -----\nEpoch: 3/11 \tTrain Loss: 0.319417\nTrain accuracy: (90.90%) with std:(0.09)\nTest accuracy: (89.82%) with std:(0.09)\n----- Model Evaluation -----\nEpoch: 4/11 \tTrain Loss: 0.253230\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions = np.mean(preds,axis=0)\n",
        "final_predictions.shape"
      ],
      "metadata": {
        "id": "nLfpw482B1qy",
        "execution": {
          "iopub.status.busy": "2023-05-21T19:00:42.941044Z",
          "iopub.execute_input": "2023-05-21T19:00:42.941468Z",
          "iopub.status.idle": "2023-05-21T19:00:42.953479Z",
          "shell.execute_reply.started": "2023-05-21T19:00:42.941436Z",
          "shell.execute_reply": "2023-05-21T19:00:42.952482Z"
        },
        "trusted": true,
        "outputId": "3128401e-ff44-4922-ae2a-cc9d859aee95"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 52,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(3774,)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = [test_data.file_list[i][-1].split('/')[-1] for i in range(len(test_data.file_list)) ]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T19:00:46.514845Z",
          "iopub.execute_input": "2023-05-21T19:00:46.515321Z",
          "iopub.status.idle": "2023-05-21T19:00:46.524023Z",
          "shell.execute_reply.started": "2023-05-21T19:00:46.515282Z",
          "shell.execute_reply": "2023-05-21T19:00:46.522856Z"
        },
        "trusted": true,
        "id": "BsDwGPPC1lVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.read_csv('/kaggle/input/ammi-2023-convnets/sample_submission_file.csv')\n",
        "sample['Id'] = name"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T19:00:47.715088Z",
          "iopub.execute_input": "2023-05-21T19:00:47.715445Z",
          "iopub.status.idle": "2023-05-21T19:00:47.735830Z",
          "shell.execute_reply.started": "2023-05-21T19:00:47.715415Z",
          "shell.execute_reply": "2023-05-21T19:00:47.734817Z"
        },
        "trusted": true,
        "id": "pHPOEnNv1lVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {0: 'cmd', 1: 'cbb', 2: 'cbsd', 3: 'healthy', 4: 'cgm'}\n",
        "new_preds = [mapping[int(pred)] for pred in final_predictions]\n",
        "sample['Category'] = new_preds\n",
        "sample.to_csv('DD10_ResNext_EfficientnetF5.csv', index=False)\n",
        "sample.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T19:01:04.066099Z",
          "iopub.execute_input": "2023-05-21T19:01:04.066465Z",
          "iopub.status.idle": "2023-05-21T19:01:04.093073Z",
          "shell.execute_reply.started": "2023-05-21T19:01:04.066436Z",
          "shell.execute_reply": "2023-05-21T19:01:04.092031Z"
        },
        "trusted": true,
        "id": "0Zdt0kNa1lVS",
        "outputId": "33b362d8-6d34-4176-cd00-be93a48454e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 55,
          "output_type": "execute_result",
          "data": {
            "text/plain": "  Category                 Id\n0      cgm  test-img-1448.jpg\n1      cmd   test-img-768.jpg\n2      cmd  test-img-3481.jpg\n3      cmd  test-img-1475.jpg\n4      cgm  test-img-2498.jpg",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cgm</td>\n      <td>test-img-1448.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cmd</td>\n      <td>test-img-768.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cmd</td>\n      <td>test-img-3481.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cmd</td>\n      <td>test-img-1475.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cgm</td>\n      <td>test-img-2498.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iZNjDZMi1lVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P7s1Z6gzB1qy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}